{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6b63277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specific hypothesis:\n",
      "Word_freq_make: 0\n",
      " Word_freq_address: 0\n",
      " Word_freq_all: 0\n",
      " Word_freq_3d: 0\n",
      " Word_freq_our: 0\n",
      " Word_freq_over: 0\n",
      " Word_freq_remove: 0\n",
      " Word_freq_internet: 0\n",
      " Word_freq_order: 0\n",
      " Word_freq_mail: 0\n",
      " Word_freq_receive: 0\n",
      " Word_freq_will: 0\n",
      " Word_freq_people: 0\n",
      " Word_freq_report: 0\n",
      " Word_freq_addresses: 0\n",
      " Word_freq_free: 0\n",
      " Word_freq_business: 0\n",
      " Word_freq_email: 0\n",
      " Word_freq_you: 0\n",
      " Word_freq_credit: 0\n",
      " Word_freq_your: 0\n",
      " Word_freq_font: 0\n",
      " Word_freq_000: 0\n",
      " Word_freq_money: 0\n",
      " Word_freq_hp: 0\n",
      " Word_freq_hpl: 0\n",
      " Word_freq_george: 0\n",
      " Word_freq_650: 0\n",
      " Word_freq_lab: 0\n",
      " Word_freq_labs: 0\n",
      " Word_freq_telnet: 0\n",
      " Word_freq_857: 0\n",
      " Word_freq_data: 0\n",
      " Word_freq_415: 0\n",
      " Word_freq_85: 0\n",
      " Word_freq_technology: 0\n",
      " Word_freq_1999: 0\n",
      " Word_freq_parts: 0\n",
      " Word_freq_pm: 0\n",
      " Word_freq_direct: 0\n",
      " Word_freq_cs: 0\n",
      " Word_freq_meeting: 0\n",
      " Word_freq_original: 0\n",
      " Word_freq_project: 0\n",
      " Word_freq_re: 0\n",
      " Word_freq_edu: 0\n",
      " Word_freq_table: 0\n",
      " Word_freq_conference: 0\n",
      " Char_freq1: 0\n",
      " Char_freq2: 0\n",
      " Char_freq3: 0\n",
      " Char_freq4: 0\n",
      " Char_freq5: 0\n",
      " Char_freq6: 0\n",
      " Capital_run_length_average: 0\n",
      " Capital_run_length_longest: 0\n",
      " Capital_run_length_total: 0\n",
      "Specific bounds:\n",
      "Word_freq_make: 0.0\n",
      " Word_freq_address: 0.0\n",
      " Word_freq_all: 0.0\n",
      " Word_freq_3d: 0.0\n",
      " Word_freq_our: 0.0\n",
      " Word_freq_over: 0.0\n",
      " Word_freq_remove: 0.0\n",
      " Word_freq_internet: 0.0\n",
      " Word_freq_order: 0.0\n",
      " Word_freq_mail: 0.0\n",
      " Word_freq_receive: 0.0\n",
      " Word_freq_will: 0.0\n",
      " Word_freq_people: 0.0\n",
      " Word_freq_report: 0.0\n",
      " Word_freq_addresses: 0.0\n",
      " Word_freq_free: 0.0\n",
      " Word_freq_business: 0.0\n",
      " Word_freq_email: 0.0\n",
      " Word_freq_you: 0.0\n",
      " Word_freq_credit: 0.0\n",
      " Word_freq_your: 0.0\n",
      " Word_freq_font: 0.0\n",
      " Word_freq_000: 0.0\n",
      " Word_freq_money: 0.0\n",
      " Word_freq_hp: 0.0\n",
      " Word_freq_hpl: 0.0\n",
      " Word_freq_george: 0.0\n",
      " Word_freq_650: 0.0\n",
      " Word_freq_lab: 0.0\n",
      " Word_freq_labs: 0.0\n",
      " Word_freq_telnet: 0.0\n",
      " Word_freq_857: 0.0\n",
      " Word_freq_data: 0.0\n",
      " Word_freq_415: 0.0\n",
      " Word_freq_85: 0.0\n",
      " Word_freq_technology: 0.0\n",
      " Word_freq_1999: 0.0\n",
      " Word_freq_parts: 0.0\n",
      " Word_freq_pm: 0.0\n",
      " Word_freq_direct: 0.0\n",
      " Word_freq_cs: 0.0\n",
      " Word_freq_meeting: 0.0\n",
      " Word_freq_original: 0.0\n",
      " Word_freq_project: 0.0\n",
      " Word_freq_re: 0.0\n",
      " Word_freq_edu: 0.0\n",
      " Word_freq_table: 0.0\n",
      " Word_freq_conference: 0.0\n",
      " Char_freq1: 0.0\n",
      " Char_freq2: 0.0\n",
      " Char_freq3: 0.0\n",
      " Char_freq4: 0.0\n",
      " Char_freq5: 0.0\n",
      " Char_freq6: 0.0\n",
      " Capital_run_length_average: 0.0\n",
      " Capital_run_length_longest: 0.0\n",
      " Capital_run_length_total: 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the spambase dataset\n",
    "spambase = pd.read_csv('data/spambase.csv')\n",
    "\n",
    "# Separate the dataset into features (X) and labels (y)\n",
    "X = spambase.iloc[:, :-1]\n",
    "y = spambase.iloc[:, -1]\n",
    "\n",
    "X_pos = spambase[spambase['spam'] == 1]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train,_, y_train, _ =train_test_split(X_pos.iloc[:, :-1], X_pos.iloc[:, -1], test_size=0.4, random_state=0)\n",
    "_,X_test,_,y_test= train_test_split(X,y, test_size=0.4, random_state=0)\n",
    "\n",
    "# Discretize the training set using equal-width binning\n",
    "num_bins = 10\n",
    "bin_width = np.ptp(X_train, axis=0) / num_bins\n",
    "X_train_discrete = (X_train / bin_width).apply(np.floor).astype(int)\n",
    "\n",
    "# Discretize the testing set using the extracted ranges from the training set\n",
    "X_test_discrete = (X_test / bin_width).apply(np.floor).astype(int)\n",
    "\n",
    "# Initialize the specific hypothesis to the first row of the training set\n",
    "specific_hypo = X_train_discrete[0:1]\n",
    "\n",
    "# Iterate over the training examples\n",
    "for i in range(1, len(X_train_discrete)):\n",
    "  # Iterate over the attributes\n",
    "  for j in range(len(specific_hypo.columns)):\n",
    "    # If the attribute value does not match the corresponding value in the training example, set it to 0\n",
    "    if specific_hypo.iloc[0, j] != X_train_discrete.iloc[i, j]:\n",
    "       specific_hypo.iloc[0, j] = 0\n",
    "\n",
    "# Calculate the accuracy of the specific hypothesis on the testing set\n",
    "num_correct = 0\n",
    "for i in range(len(X_test_discrete)):\n",
    "  # Iterate over the attributes\n",
    "  for j in range(len(specific_hypo.columns)):\n",
    "    # If the attribute value does not match the corresponding value in the testing example, increment the false example count\n",
    "    if specific_hypo.iloc[0, j] != X_test_discrete.iloc[i, j]:\n",
    "      num_correct += 1\n",
    "      break\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the bounds for the class attributes. \n",
    "#It converts the discrete values of the specific hypothesis back to the original continuous values,\n",
    "#and thus obtain the specific bounds for the class attributes.\n",
    "bounds = specific_hypo * bin_width\n",
    "\n",
    "\n",
    "\n",
    "print(\"Specific hypothesis:\")\n",
    "for i,col in enumerate(specific_hypo.columns):\n",
    "    print(f'{col}: {specific_hypo.iloc[0, i]}')\n",
    "\n",
    "print(\"Specific bounds:\")\n",
    "for i,col in enumerate(specific_hypo.columns):\n",
    "    print(f'{col}: {bounds.iloc[0, i]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abc2726c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "accuracy = num_correct / len(X_test_discrete)\n",
    "# Print the results\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35f082fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd4d31b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
